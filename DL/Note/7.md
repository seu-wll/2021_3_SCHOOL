# 7.6 ResNET

残差网络的意义不只是在于增加了层的个数，更是在于其增加了残差的学习办法。通过构造一个恒等映射，使得反向传播出来的值不会为0.

根据网络结构，我们的网络映射为：
$$
x_{L}=x_{l}+\sum_{i=l}^{L-1} F\left(x_{i}, W_{i}\right)
$$

利用链式规则，可以求得反向过程的梯度:
$$
\frac{\partial l o s s}{\partial x_{l}}=\frac{\partial l o s s}{\partial x_{L}} \cdot \frac{\partial x_{L}}{\partial x_{l}}=\frac{\partial l o s s}{\partial x_{L}} \cdot\left(1+\frac{\partial}{\partial x_{L}} \sum_{i=l}^{L-1} F\left(x_{i}, W_{i}\right)\right)
$$
比较难以直接到0，所以不容易梯度消失。