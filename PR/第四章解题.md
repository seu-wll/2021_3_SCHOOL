# 第四章整理

[非参数估计一](https://zhuanlan.zhihu.com/p/60985229)

[非参数估计二（窗口函数）](https://zhuanlan.zhihu.com/p/60985229)

[非参数估计三（k邻近）](https://zhuanlan.zhihu.com/p/61398279)



整理下第四章别到时候整理显得非常狼狈罢了。到时候拿到题目之后解题应该会单独被放出来吧。

### 非参数估计的两种解法非参数估计

要的也是去估计样本属于哪个类，用的是两种办法。对于每个类来说，样本属于该类的密度函数可以这么定义：

$$
p_{n}(\mathbf{x})=\frac{k_{n} / n}{V_{n}}
$$
怎么来的不用管，看推导就行，那么显然这个概率密度就和$k_n$和$V_n$相关嘛,固定$V_n$我们称之为Parzen Windows方法，而固定$k_n$则是knn算法。

### Parzen Windows

定义：
$$
V_{n}=h_{n .}^{d}
$$
可以得到概率密度的表达式：
$$
p_{n}(\mathbf{x})=\frac{1}{n} \sum_{i=1}^{n} \frac{1}{V_{n}} \varphi\left(\frac{\mathbf{x}-\mathbf{x}_{i}}{h_{n}}\right)
$$
假设：
$$
p_{n}(\mathbf{x})=\frac{1}{n} \sum_{i=1}^{n} \delta_{n}\left(\mathbf{x}-\mathbf{x}_{i}\right), \text { where } \delta_{n}(\mathbf{x})=\frac{1}{h_{n}^{d}} \varphi\left(\frac{\mathbf{x}}{h_{n}}\right)
$$
然后可以得到规律了：

![image-20210419133741588](B:\Tpora\image-20210419133741588.png)

具体反映到图像上可以自己去看：

![image-20210419133800612](B:\Tpora\image-20210419133800612.png)

### KNN

比较简单了,首先做两个假设：
$$
\begin{array}{l}
\lim _{n \rightarrow \infty} k_{n}=\infty \\
\lim _{n \rightarrow \infty} \frac{k_{n}}{n}=0
\end{array}
$$
然后就可以定义$k_n$了，比较好的效果是,定义：
$$
k_{n}=\sqrt{n}
$$
然后对每个点扩展长度到包括k个样本，然后画出曲线，如果在定义域上收敛，那么就可以用归一化得到概率密度函数。ppt上有一维的和二维的函数图像。

### Nearest Neighbor Rule &Distance Metric

这里knn和之前的不是一个东西，这个是直接拿来分类的。

判别分类的准则，除了贝叶斯还可以有knn邻近准则，谁跟我进我跟谁。当类别足够大的时候，可以理论上证明效果不错。



但是复杂度比较大，那么就可以用降维、在叶节点寻找，剪枝等办法了。具体不展开。



然后还介绍了一大堆计算距离的办法。以及什么样的函数可以被称作为距离——满足4大规则即可。

